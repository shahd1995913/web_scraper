# Web Scraping
## We can consume web sites with our eyes, ears and fingers. But how about getting your computer to consume it for you?

## Execute
## Use requests and beautiful soup libraries
## Inspect a web pages content to determine an effective scraping method
## Execute web scraper from CLI

## Scrape a Wikipedia page and record which passages need citations.
- [x] E.g. History of Mexico has a few “citations needed”.  Done
- [x] Your web scraper should report the number of citations needed. Done 
- [x] Report function must be named get_citations_needed_report. Done 
- [x] get_citations_needed_report takes in a url and returns a string , the string should be formatted with each citation needed on own line, in order found. Done


## The pull requst : https://github.com/shahd1995913/web_scraper/pull/1
